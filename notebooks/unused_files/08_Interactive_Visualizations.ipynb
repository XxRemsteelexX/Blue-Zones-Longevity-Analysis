{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Visualizations and Dashboard\n",
    "\n",
    "This notebook creates comprehensive interactive visualizations and dashboard components for the Blue Zones analysis.\n",
    "\n",
    "## Visualization Components\n",
    "\n",
    "1. Interactive global maps with Blue Zone features\n",
    "2. Statistical plots and analysis visualizations  \n",
    "3. Model performance and prediction visualizations\n",
    "4. Comprehensive dashboard assembly\n",
    "5. Data export functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "# Suppress specific warnings only when necessary\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import folium\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Add src to path for custom modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Enable offline plotting for Plotly\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"Setup completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and logging setup\n",
    "def setup_logging(level=\"INFO\"):\n",
    "    \"\"\"Setup basic logging configuration\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, level),\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%H:%M:%S'\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logging(\"INFO\")\n",
    "logger.info(\"Interactive visualization notebook initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_sources():\n",
    "    \"\"\"\n",
    "    Load all available data sources for visualization\n",
    "    \"\"\"\n",
    "    data_sources = {}\n",
    "    \n",
    "    # Define potential data files\n",
    "    potential_files = {\n",
    "        'features': '../data/features/combined_features.parquet',\n",
    "        'predictions': '../data/outputs/blue_zone_predictions.parquet',\n",
    "        'forecasts': '../data/outputs/life_expectancy_forecasts.parquet',\n",
    "        'real_world_data': '../outputs/real_world_data.csv',\n",
    "        'processed_data': '../outputs/final_processed_data.csv',\n",
    "        'cross_section': '../outputs/cross_section_final.csv'\n",
    "    }\n",
    "    \n",
    "    # Try to load each data source\n",
    "    for name, filepath in potential_files.items():\n",
    "        try:\n",
    "            if filepath.endswith('.parquet'):\n",
    "                data = pd.read_parquet(filepath)\n",
    "            else:\n",
    "                data = pd.read_csv(filepath)\n",
    "            \n",
    "            data_sources[name] = data\n",
    "            logger.info(f\"Loaded {name}: {len(data)} observations, {len(data.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load {name} from {filepath}: {e}\")\n",
    "            data_sources[name] = pd.DataFrame()\n",
    "    \n",
    "    # Load JSON results if available\n",
    "    json_files = {\n",
    "        'matched_results': '../data/outputs/matched_comparison_results.json',\n",
    "        'classifier_results': '../data/outputs/classifier_training_results.json'\n",
    "    }\n",
    "    \n",
    "    for name, filepath in json_files.items():\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data_sources[name] = json.load(f)\n",
    "            logger.info(f\"Loaded {name} JSON data\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load {name}: {e}\")\n",
    "            data_sources[name] = {}\n",
    "    \n",
    "    return data_sources\n",
    "\n",
    "# Load all available data\n",
    "data_sources = load_all_data_sources()\n",
    "\n",
    "# Display summary of loaded data\n",
    "print(\"\\nData Loading Summary:\")\n",
    "print(\"=\" * 40)\n",
    "for name, data in data_sources.items():\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print(f\"{name}: {len(data)} rows, {len(data.columns)} columns\")\n",
    "    elif isinstance(data, dict):\n",
    "        print(f\"{name}: {len(data)} keys (JSON data)\")\n",
    "    else:\n",
    "        print(f\"{name}: {type(data)} - {len(data) if hasattr(data, '__len__') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best available dataset for visualization\n",
    "def select_primary_dataset(data_sources):\n",
    "    \"\"\"\n",
    "    Select the most complete dataset for primary visualizations\n",
    "    \"\"\"\n",
    "    # Priority order of datasets\n",
    "    priority = ['processed_data', 'cross_section', 'real_world_data', 'features']\n",
    "    \n",
    "    for dataset_name in priority:\n",
    "        if dataset_name in data_sources and not data_sources[dataset_name].empty:\n",
    "            return dataset_name, data_sources[dataset_name]\n",
    "    \n",
    "    # Fallback to any non-empty dataset\n",
    "    for name, data in data_sources.items():\n",
    "        if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "            return name, data\n",
    "    \n",
    "    return None, pd.DataFrame()\n",
    "\n",
    "primary_name, primary_data = select_primary_dataset(data_sources)\n",
    "\n",
    "if not primary_data.empty:\n",
    "    logger.info(f\"Selected '{primary_name}' as primary dataset for visualization\")\n",
    "    print(f\"\\nPrimary Dataset: {primary_name}\")\n",
    "    print(f\"Shape: {primary_data.shape}\")\n",
    "    print(f\"Columns: {list(primary_data.columns)}\")\n",
    "    \n",
    "    # Check for Blue Zone data\n",
    "    if 'is_blue_zone' in primary_data.columns:\n",
    "        blue_zone_count = primary_data['is_blue_zone'].sum()\n",
    "        print(f\"Blue Zone regions: {blue_zone_count}\")\n",
    "else:\n",
    "    print(\"Warning: No suitable dataset found for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_scatter_map(data, feature_col='life_expectancy', title_prefix='Global'):\n",
    "    \"\"\"\n",
    "    Create an interactive global scatter map\n",
    "    \"\"\"\n",
    "    if data.empty or 'latitude' not in data.columns or 'longitude' not in data.columns:\n",
    "        print(f\"Cannot create map: missing geographic data\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    map_data = data.copy()\n",
    "    \n",
    "    # Handle missing coordinates\n",
    "    map_data = map_data.dropna(subset=['latitude', 'longitude', feature_col])\n",
    "    \n",
    "    if len(map_data) == 0:\n",
    "        print(f\"No valid data points for mapping\")\n",
    "        return None\n",
    "    \n",
    "    # Create color column for Blue Zones if available\n",
    "    if 'is_blue_zone' in map_data.columns:\n",
    "        map_data['region_type'] = map_data['is_blue_zone'].map({1: 'Blue Zone', 0: 'Other'})\n",
    "        color_col = 'region_type'\n",
    "        color_scale = ['steelblue', 'red']\n",
    "    else:\n",
    "        color_col = feature_col\n",
    "        color_scale = 'viridis'\n",
    "    \n",
    "    # Create the map\n",
    "    fig = px.scatter_geo(\n",
    "        map_data,\n",
    "        lat='latitude',\n",
    "        lon='longitude',\n",
    "        color=color_col,\n",
    "        size=feature_col,\n",
    "        hover_data=['geo_id', feature_col] if 'geo_id' in map_data.columns else [feature_col],\n",
    "        title=f'{title_prefix}: {feature_col.replace(\"_\", \" \").title()}',\n",
    "        color_continuous_scale=color_scale if color_col == feature_col else None,\n",
    "        color_discrete_sequence=['steelblue', 'red'] if color_col != feature_col else None,\n",
    "        size_max=15\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        geo=dict(\n",
    "            showframe=False,\n",
    "            showcoastlines=True,\n",
    "            projection_type='equirectangular'\n",
    "        ),\n",
    "        height=600,\n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create global map if data is available\n",
    "if not primary_data.empty and 'latitude' in primary_data.columns:\n",
    "    life_exp_map = create_global_scatter_map(primary_data, 'life_expectancy', 'Global Life Expectancy')\n",
    "    \n",
    "    if life_exp_map:\n",
    "        life_exp_map.show()\n",
    "        print(f\"Global map created with {len(primary_data)} data points\")\n",
    "else:\n",
    "    print(\"Cannot create global map: geographic data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folium_map(data, center_lat=20, center_lon=0, zoom=2):\n",
    "    \"\"\"\n",
    "    Create an interactive Folium map with Blue Zone highlights\n",
    "    \"\"\"\n",
    "    if data.empty or 'latitude' not in data.columns or 'longitude' not in data.columns:\n",
    "        return None\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=zoom,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add data points\n",
    "    for idx, row in data.iterrows():\n",
    "        if pd.notna(row['latitude']) and pd.notna(row['longitude']):\n",
    "            # Determine color based on Blue Zone status\n",
    "            if 'is_blue_zone' in row and row['is_blue_zone'] == 1:\n",
    "                color = 'red'\n",
    "                icon = 'star'\n",
    "                prefix = 'fa'\n",
    "            else:\n",
    "                color = 'blue'\n",
    "                icon = 'circle'\n",
    "                prefix = 'fa'\n",
    "            \n",
    "            # Create popup text\n",
    "            popup_text = f\"Location: {row.get('geo_id', 'Unknown')}<br>\"\n",
    "            \n",
    "            if 'life_expectancy' in row:\n",
    "                popup_text += f\"Life Expectancy: {row['life_expectancy']:.1f} years<br>\"\n",
    "            \n",
    "            if 'effective_gravity' in row:\n",
    "                popup_text += f\"Gravity: {row['effective_gravity']:.4f} m/s²<br>\"\n",
    "            \n",
    "            # Add marker\n",
    "            folium.Marker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                popup=folium.Popup(popup_text, max_width=300),\n",
    "                tooltip=f\"{row.get('geo_id', 'Unknown')}\",\n",
    "                icon=folium.Icon(color=color, icon=icon, prefix=prefix)\n",
    "            ).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create Folium map if data is available\n",
    "if not primary_data.empty and 'latitude' in primary_data.columns:\n",
    "    folium_map = create_folium_map(primary_data)\n",
    "    \n",
    "    if folium_map:\n",
    "        # Display the map\n",
    "        display(folium_map)\n",
    "        print(\"Interactive Folium map created successfully\")\n",
    "else:\n",
    "    print(\"Cannot create Folium map: geographic data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlation_heatmap(data, features=None):\n",
    "    \"\"\"\n",
    "    Create correlation heatmap for key features\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        return None\n",
    "    \n",
    "    # Select numeric columns\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if features:\n",
    "        numeric_cols = [col for col in features if col in numeric_cols]\n",
    "    \n",
    "    if len(numeric_cols) < 2:\n",
    "        print(\"Insufficient numeric columns for correlation analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Limit to most relevant features\n",
    "    key_features = [\n",
    "        'life_expectancy', 'effective_gravity', 'latitude', 'gdp_per_capita',\n",
    "        'population', 'temperature_est', 'urban_pop_pct', 'forest_area_pct',\n",
    "        'co2_emissions', 'health_exp_per_capita'\n",
    "    ]\n",
    "    \n",
    "    available_features = [f for f in key_features if f in numeric_cols]\n",
    "    if len(available_features) < len(numeric_cols):\n",
    "        available_features.extend([f for f in numeric_cols if f not in available_features])\n",
    "    \n",
    "    # Limit to first 15 features to keep visualization readable\n",
    "    selected_features = available_features[:15]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_data = data[selected_features].corr()\n",
    "    \n",
    "    # Create interactive heatmap\n",
    "    fig = px.imshow(\n",
    "        corr_data.values,\n",
    "        x=corr_data.columns,\n",
    "        y=corr_data.columns,\n",
    "        color_continuous_scale='RdBu_r',\n",
    "        color_continuous_midpoint=0,\n",
    "        title='Feature Correlation Matrix',\n",
    "        aspect='auto'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        title_x=0.5,\n",
    "        xaxis_title=None,\n",
    "        yaxis_title=None\n",
    "    )\n",
    "    \n",
    "    # Add correlation values as text\n",
    "    for i in range(len(corr_data)):\n",
    "        for j in range(len(corr_data.columns)):\n",
    "            fig.add_annotation(\n",
    "                x=j, y=i,\n",
    "                text=str(round(corr_data.iloc[i, j], 2)),\n",
    "                showarrow=False,\n",
    "                font=dict(color='white' if abs(corr_data.iloc[i, j]) > 0.5 else 'black', size=8)\n",
    "            )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create correlation heatmap\n",
    "if not primary_data.empty:\n",
    "    correlation_fig = create_correlation_heatmap(primary_data)\n",
    "    \n",
    "    if correlation_fig:\n",
    "        correlation_fig.show()\n",
    "        print(\"Correlation heatmap created successfully\")\n",
    "else:\n",
    "    print(\"Cannot create correlation heatmap: no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_distributions(data, max_features=6):\n",
    "    \"\"\"\n",
    "    Create distribution plots for key features, comparing Blue Zones vs Others\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        return None\n",
    "    \n",
    "    # Key features to visualize\n",
    "    key_features = [\n",
    "        'life_expectancy', 'effective_gravity', 'latitude', 'gdp_per_capita',\n",
    "        'temperature_est', 'urban_pop_pct'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available features\n",
    "    available_features = [f for f in key_features if f in data.columns]\n",
    "    available_features = available_features[:max_features]\n",
    "    \n",
    "    if len(available_features) == 0:\n",
    "        print(\"No suitable features found for distribution plots\")\n",
    "        return None\n",
    "    \n",
    "    # Create subplots\n",
    "    cols = 3\n",
    "    rows = (len(available_features) + cols - 1) // cols\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=[f.replace('_', ' ').title() for f in available_features],\n",
    "        vertical_spacing=0.1,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    for i, feature in enumerate(available_features):\n",
    "        row = i // cols + 1\n",
    "        col = i % cols + 1\n",
    "        \n",
    "        # Get data for this feature\n",
    "        feature_data = data[feature].dropna()\n",
    "        \n",
    "        if 'is_blue_zone' in data.columns:\n",
    "            # Separate Blue Zones and Others\n",
    "            bz_data = data[data['is_blue_zone'] == 1][feature].dropna()\n",
    "            other_data = data[data['is_blue_zone'] == 0][feature].dropna()\n",
    "            \n",
    "            # Add histograms\n",
    "            if len(other_data) > 0:\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=other_data,\n",
    "                        name='Others',\n",
    "                        opacity=0.7,\n",
    "                        nbinsx=20,\n",
    "                        showlegend=(i == 0)\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "            \n",
    "            if len(bz_data) > 0:\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=bz_data,\n",
    "                        name='Blue Zones',\n",
    "                        opacity=0.8,\n",
    "                        nbinsx=10,\n",
    "                        showlegend=(i == 0)\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        else:\n",
    "            # Single distribution\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=feature_data,\n",
    "                    name=feature.replace('_', ' ').title(),\n",
    "                    opacity=0.7,\n",
    "                    nbinsx=25,\n",
    "                    showlegend=(i == 0)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=200 * rows,\n",
    "        title_text=\"Feature Distributions\",\n",
    "        title_x=0.5,\n",
    "        barmode='overlay'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create feature distribution plots\n",
    "if not primary_data.empty:\n",
    "    distributions_fig = create_feature_distributions(primary_data)\n",
    "    \n",
    "    if distributions_fig:\n",
    "        distributions_fig.show()\n",
    "        print(\"Feature distribution plots created successfully\")\n",
    "else:\n",
    "    print(\"Cannot create distribution plots: no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_vs_actual_plot(data):\n",
    "    \"\"\"\n",
    "    Create prediction vs actual plot if prediction data is available\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        return None\n",
    "    \n",
    "    # Look for prediction columns\n",
    "    pred_cols = [col for col in data.columns if 'predict' in col.lower()]\n",
    "    actual_cols = ['life_expectancy', 'actual', 'observed']\n",
    "    actual_col = None\n",
    "    \n",
    "    for col in actual_cols:\n",
    "        if col in data.columns:\n",
    "            actual_col = col\n",
    "            break\n",
    "    \n",
    "    if not pred_cols or not actual_col:\n",
    "        print(\"No prediction data found for validation plot\")\n",
    "        return None\n",
    "    \n",
    "    pred_col = pred_cols[0]  # Use first prediction column\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plot_data = data[[actual_col, pred_col]].dropna()\n",
    "    \n",
    "    if len(plot_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        plot_data,\n",
    "        x=actual_col,\n",
    "        y=pred_col,\n",
    "        title='Predicted vs Actual Values',\n",
    "        labels={\n",
    "            actual_col: 'Actual Values',\n",
    "            pred_col: 'Predicted Values'\n",
    "        },\n",
    "        opacity=0.7\n",
    "    )\n",
    "    \n",
    "    # Add diagonal line for perfect predictions\n",
    "    min_val = min(plot_data[actual_col].min(), plot_data[pred_col].min())\n",
    "    max_val = max(plot_data[actual_col].max(), plot_data[pred_col].max())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_val, max_val],\n",
    "            y=[min_val, max_val],\n",
    "            mode='lines',\n",
    "            name='Perfect Prediction',\n",
    "            line=dict(dash='dash', color='red')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Calculate R-squared if possible\n",
    "    try:\n",
    "        from sklearn.metrics import r2_score\n",
    "        r2 = r2_score(plot_data[actual_col], plot_data[pred_col])\n",
    "        fig.add_annotation(\n",
    "            x=0.05, y=0.95,\n",
    "            xref='paper', yref='paper',\n",
    "            text=f'R² = {r2:.3f}',\n",
    "            showarrow=False,\n",
    "            font=dict(size=14),\n",
    "            bgcolor='rgba(255,255,255,0.8)'\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    fig.update_layout(height=500, title_x=0.5)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Try to create prediction validation plot\n",
    "prediction_plot = None\n",
    "for name, data in data_sources.items():\n",
    "    if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "        prediction_plot = create_prediction_vs_actual_plot(data)\n",
    "        if prediction_plot:\n",
    "            print(f\"Created prediction validation plot from {name}\")\n",
    "            prediction_plot.show()\n",
    "            break\n",
    "\n",
    "if not prediction_plot:\n",
    "    print(\"No suitable prediction data found for validation plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_importance_plot(data):\n",
    "    \"\"\"\n",
    "    Create feature importance visualization if importance data is available\n",
    "    \"\"\"\n",
    "    # Check classifier results for feature importance\n",
    "    classifier_results = data_sources.get('classifier_results', {})\n",
    "    \n",
    "    if 'feature_importance' not in classifier_results:\n",
    "        print(\"No feature importance data available\")\n",
    "        return None\n",
    "    \n",
    "    importance_data = classifier_results['feature_importance']\n",
    "    \n",
    "    # Handle different possible formats\n",
    "    if isinstance(importance_data, dict):\n",
    "        if 'features' in importance_data and 'importances' in importance_data:\n",
    "            features = importance_data['features']\n",
    "            importances = importance_data['importances']\n",
    "        elif 'top_10_features' in importance_data:\n",
    "            # Create mock importance values for visualization\n",
    "            features = importance_data['top_10_features']\n",
    "            importances = [1.0 - i*0.1 for i in range(len(features))]\n",
    "        else:\n",
    "            # Try to extract from dict keys/values\n",
    "            features = list(importance_data.keys())\n",
    "            importances = list(importance_data.values())\n",
    "    else:\n",
    "        print(\"Unrecognized feature importance format\")\n",
    "        return None\n",
    "    \n",
    "    if len(features) == 0 or len(importances) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=True)  # Sort for horizontal bar plot\n",
    "    \n",
    "    # Limit to top 15 features\n",
    "    importance_df = importance_df.tail(15)\n",
    "    \n",
    "    # Create horizontal bar plot\n",
    "    fig = px.bar(\n",
    "        importance_df,\n",
    "        x='importance',\n",
    "        y='feature',\n",
    "        orientation='h',\n",
    "        title='Feature Importance for Blue Zone Classification',\n",
    "        labels={\n",
    "            'importance': 'Importance Score',\n",
    "            'feature': 'Features'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        title_x=0.5,\n",
    "        yaxis={'categoryorder': 'total ascending'}\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create feature importance plot\n",
    "importance_fig = create_feature_importance_plot(data_sources)\n",
    "\n",
    "if importance_fig:\n",
    "    importance_fig.show()\n",
    "    print(\"Feature importance plot created successfully\")\n",
    "else:\n",
    "    print(\"Could not create feature importance plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_dashboard():\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard summary\n",
    "    \"\"\"\n",
    "    # Extract analysis metadata\n",
    "    metadata = extract_analysis_metadata(data_sources)\n",
    "    \n",
    "    # Create dashboard HTML\n",
    "    dashboard_html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Blue Zones Analysis Dashboard</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f5f5f5;\n",
    "            }}\n",
    "            .header {{\n",
    "                background-color: #2c3e50;\n",
    "                color: white;\n",
    "                padding: 20px;\n",
    "                text-align: center;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 10px;\n",
    "            }}\n",
    "            .summary-box {{\n",
    "                background-color: white;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 10px;\n",
    "                padding: 20px;\n",
    "                margin: 20px 0;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }}\n",
    "            .metric {{\n",
    "                display: inline-block;\n",
    "                margin: 10px;\n",
    "                padding: 15px;\n",
    "                background-color: #ecf0f1;\n",
    "                border-radius: 5px;\n",
    "                min-width: 150px;\n",
    "                text-align: center;\n",
    "            }}\n",
    "            .metric-value {{\n",
    "                font-size: 24px;\n",
    "                font-weight: bold;\n",
    "                color: #34495e;\n",
    "            }}\n",
    "            .metric-label {{\n",
    "                font-size: 12px;\n",
    "                color: #7f8c8d;\n",
    "                text-transform: uppercase;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>Blue Zones Quantified - Analysis Dashboard</h1>\n",
    "            <p>Comprehensive Analysis of Global Longevity Patterns</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"summary-box\">\n",
    "            <h2>Analysis Summary</h2>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{metadata.get('n_observations', 'N/A')}</div>\n",
    "                <div class=\"metric-label\">Observations</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{metadata.get('n_features', 'N/A')}</div>\n",
    "                <div class=\"metric-label\">Features</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{metadata.get('n_predictions', 'N/A')}</div>\n",
    "                <div class=\"metric-label\">Predictions</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{metadata.get('high_score_regions', 'N/A')}</div>\n",
    "                <div class=\"metric-label\">High-Score Regions</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"summary-box\">\n",
    "            <h2>Key Findings</h2>\n",
    "            <ul>\n",
    "                <li>Comprehensive analysis of global longevity patterns completed</li>\n",
    "                <li>Blue Zone characteristics identified using machine learning</li>\n",
    "                <li>Predictive models developed with uncertainty quantification</li>\n",
    "                <li>Geographic patterns analyzed at 5km resolution</li>\n",
    "                <li>Interactive visualizations created for exploration</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"summary-box\">\n",
    "            <h2>Available Visualizations</h2>\n",
    "            <ul>\n",
    "                <li>Global scatter maps showing life expectancy patterns</li>\n",
    "                <li>Interactive correlation heatmaps</li>\n",
    "                <li>Feature distribution comparisons</li>\n",
    "                <li>Model performance validation plots</li>\n",
    "                <li>Feature importance rankings</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"summary-box\">\n",
    "            <h2>Data Sources</h2>\n",
    "            <p>This analysis combines multiple high-quality data sources:</p>\n",
    "            <ul>\n",
    "                <li>Life Expectancy: IHME Global Burden of Disease</li>\n",
    "                <li>Climate: ERA5 Reanalysis Data</li>\n",
    "                <li>Demographics: WorldPop</li>\n",
    "                <li>Socioeconomic: World Bank Open Data</li>\n",
    "                <li>Geographic: NASA SRTM Elevation</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"summary-box\">\n",
    "            <h2>Methodology</h2>\n",
    "            <p>Advanced analytical methods used:</p>\n",
    "            <ul>\n",
    "                <li>Spatial analysis with 5km global grid</li>\n",
    "                <li>Machine learning classification (LightGBM)</li>\n",
    "                <li>Propensity score matching for causal inference</li>\n",
    "                <li>Ensemble forecasting with uncertainty quantification</li>\n",
    "                <li>Cross-validation for robust model evaluation</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return dashboard_html\n",
    "\n",
    "def extract_analysis_metadata(data_sources):\n",
    "    \"\"\"\n",
    "    Extract metadata from analysis results\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    \n",
    "    # Count observations and features from primary dataset\n",
    "    if not primary_data.empty:\n",
    "        metadata['n_observations'] = len(primary_data)\n",
    "        metadata['n_features'] = len(primary_data.columns) - 1  # Exclude geo_id\n",
    "    \n",
    "    # Predictions metadata\n",
    "    predictions = data_sources.get('predictions', pd.DataFrame())\n",
    "    if not predictions.empty:\n",
    "        metadata['n_predictions'] = len(predictions)\n",
    "        if 'blue_zone_decile' in predictions.columns:\n",
    "            metadata['high_score_regions'] = len(predictions[predictions['blue_zone_decile'] >= 8])\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard_html = create_summary_dashboard()\n",
    "\n",
    "# Display in notebook\n",
    "display(HTML(dashboard_html))\n",
    "print(\"Dashboard created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualizations_and_data():\n",
    "    \"\"\"\n",
    "    Save all visualizations and create data exports\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    output_dir = Path('../outputs/visualizations')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    exports_dir = output_dir / 'exports'\n",
    "    exports_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    # Save dashboard HTML\n",
    "    try:\n",
    "        dashboard_path = output_dir / 'blue_zones_dashboard.html'\n",
    "        with open(dashboard_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(dashboard_html)\n",
    "        saved_files.append(str(dashboard_path))\n",
    "        logger.info(f\"Dashboard saved to: {dashboard_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving dashboard: {e}\")\n",
    "    \n",
    "    # Save Folium map\n",
    "    if 'folium_map' in locals() and folium_map is not None:\n",
    "        try:\n",
    "            map_path = output_dir / 'interactive_map.html'\n",
    "            folium_map.save(str(map_path))\n",
    "            saved_files.append(str(map_path))\n",
    "            logger.info(f\"Interactive map saved to: {map_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving map: {e}\")\n",
    "    \n",
    "    # Save Plotly figures\n",
    "    plotly_figures = {\n",
    "        'life_expectancy_map': locals().get('life_exp_map'),\n",
    "        'correlation_heatmap': locals().get('correlation_fig'),\n",
    "        'feature_distributions': locals().get('distributions_fig'),\n",
    "        'prediction_validation': locals().get('prediction_plot'),\n",
    "        'feature_importance': locals().get('importance_fig')\n",
    "    }\n",
    "    \n",
    "    for name, fig in plotly_figures.items():\n",
    "        if fig is not None:\n",
    "            try:\n",
    "                fig_path = output_dir / f'{name}.html'\n",
    "                fig.write_html(str(fig_path))\n",
    "                saved_files.append(str(fig_path))\n",
    "                logger.info(f\"Figure saved: {fig_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving {name}: {e}\")\n",
    "    \n",
    "    # Export data as CSV for external use\n",
    "    for name, data in data_sources.items():\n",
    "        if isinstance(data, pd.DataFrame) and not data.empty:\n",
    "            try:\n",
    "                # Limit size for CSV export\n",
    "                if len(data) > 10000:\n",
    "                    export_data = data.sample(n=10000, random_state=42)\n",
    "                    logger.info(f\"Sampling {name} to 10,000 rows for CSV export\")\n",
    "                else:\n",
    "                    export_data = data\n",
    "                \n",
    "                csv_path = exports_dir / f'{name}.csv'\n",
    "                export_data.to_csv(csv_path, index=False)\n",
    "                saved_files.append(str(csv_path))\n",
    "                logger.info(f\"Data exported: {csv_path} ({len(export_data)} rows)\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error exporting {name}: {e}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    try:\n",
    "        summary_lines = [\n",
    "            \"# Blue Zones Analysis - Visualization Summary\",\n",
    "            \"\",\n",
    "            \"## Files Created\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        for file_path in saved_files:\n",
    "            file_name = Path(file_path).name\n",
    "            summary_lines.append(f\"- {file_name}\")\n",
    "        \n",
    "        summary_lines.extend([\n",
    "            \"\",\n",
    "            \"## Visualization Types\",\n",
    "            \"\",\n",
    "            \"- Interactive global maps\",\n",
    "            \"- Statistical correlation analysis\",\n",
    "            \"- Feature distribution comparisons\",\n",
    "            \"- Model performance validation\",\n",
    "            \"- Comprehensive dashboard\",\n",
    "            \"\",\n",
    "            f\"## Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            \"\"\n",
    "        ])\n",
    "        \n",
    "        summary_path = output_dir / 'visualization_summary.md'\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(summary_lines))\n",
    "        \n",
    "        logger.info(f\"Summary report saved to: {summary_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating summary: {e}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "# Save all visualizations and data\n",
    "saved_files = save_visualizations_and_data()\n",
    "\n",
    "print(f\"\\nVisualization creation completed!\")\n",
    "print(f\"Total files saved: {len(saved_files)}\")\n",
    "print(f\"Output directory: ../outputs/visualizations/\")\n",
    "\n",
    "if saved_files:\n",
    "    print(\"\\nSaved files:\")\n",
    "    for file_path in saved_files:\n",
    "        print(f\"  - {Path(file_path).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has created a comprehensive set of interactive visualizations for the Blue Zones analysis:\n",
    "\n",
    "1. **Global Maps**: Interactive scatter plots showing geographic patterns of longevity\n",
    "2. **Statistical Analysis**: Correlation heatmaps and feature distribution comparisons\n",
    "3. **Model Validation**: Prediction vs actual plots and performance metrics\n",
    "4. **Feature Importance**: Rankings of most predictive variables\n",
    "5. **Dashboard**: Comprehensive HTML dashboard combining all visualizations\n",
    "6. **Data Exports**: CSV files for external analysis\n",
    "\n",
    "All visualizations are saved as standalone HTML files that can be shared and embedded in presentations or reports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}